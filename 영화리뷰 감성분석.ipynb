{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "### 코드\n",
    "https://github.com/donghwan2/Text_analysis/blob/master/%EB%84%A4%EC%9D%B4%EB%B2%84%20%EC%98%81%ED%99%94%20%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D%20%EB%B0%8F%20%EA%B8%8D%EC%A0%95%2C%EB%B6%80%EC%A0%95%20%EC%98%88%EC%B8%A1%20%EB%AA%A8%EB%8D%B8.ipynb\n",
    "\n",
    "https://github.com/e9t/nsmc/\n",
    "\n",
    "\n",
    "### TfidfVectorizer\n",
    "https://datascienceschool.net/view-notebook/3e7aadbf88ed4f0d87a76f9ddc925d69/\n",
    "\n",
    "https://thinkwarelab.wordpress.com/2016/11/14/ir-tf-idf-%EC%97%90-%EB%8C%80%ED%95%B4-%EC%95%8C%EC%95%84%EB%B4%85%EC%8B%9C%EB%8B%A4/\n",
    "\n",
    "https://blog.breezymind.com/2018/03/02/sklearn-feature_extraction-text-2/\n",
    "\n",
    "https://m.blog.naver.com/PostView.nhn?blogId=samsjang&logNo=220985170721&proxyReferer=https%3A%2F%2Fwww.google.com%2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import os\n",
    "from urllib import parse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from konlpy.tag import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1_get_detail_url() :\n",
    "    site = 'https://movie.naver.com/movie/running/current.nhn?order=reserve'\n",
    "    # 현재 상영작 홈페이지 url\n",
    "    response = requests.get(site)   \n",
    "    # 사이트에 접속합니다.\n",
    "    bs = BeautifulSoup(response.content, 'html.parser')\n",
    "    # html 코드를 가져옵니다\n",
    "    a_list = bs.select('.top_thumb_lst a')\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for idx in range(10) :       # 상위 10개만 가져오기\n",
    "        href = a_list[idx].get('href')\n",
    "        a1 = parse.urlparse(href)\n",
    "        query_str = parse.parse_qs(a1.query)\n",
    "        code = query_str['code'][0]\n",
    "        df = df.append([[code]], ignore_index=True)\n",
    "        # html 코드에서 영화 코드를 가져옵니다.\n",
    "\n",
    "    df.columns = ['code']\n",
    "    df.to_csv('movie_code_list.csv', index=False, encoding='utf-8-sig')\n",
    "    # movie_code_list에 영화 코드를 저장합니다.\n",
    "\n",
    "# 영화 정보페이지로 이동하기 위해서 필요한 함수입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2_get_reple_href() :\n",
    "    code_frame = pd.read_csv('movie_code_list.csv')\n",
    "    # 영화 코드 파일을 가져옵니다.\n",
    "    code_list = code_frame['code'].tolist()\n",
    "    url_list = pd.DataFrame()\n",
    "    # url 주소를 담을 dataframe을 만듭니다.\n",
    "    \n",
    "    for code in code_list:\n",
    "        site = 'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=%s&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false' % code\n",
    "        # 파이썬 문법의 특징인데 https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=%s\n",
    "        # 이부분에 %s 로 된 부분을 뒤에 % code 값으로 대체합니다.(포맷팅이라고 합니다.)\n",
    "        # code는 영화 코드이므로 영화 코드에 맞게 영화 상세 페이지로 이동합니다.\n",
    "        url_list = url_list.append([[site]], ignore_index=True)\n",
    "\n",
    "    url_list.columns = ['url']\n",
    "    url_list.to_csv('movie_url_list.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 영화 정보 페이지 url 주소들을 movie_url_list로 저장합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step3_get_reply_data() :\n",
    "    df = pd.read_csv('movie_url_list.csv')\n",
    "    # 영화 정보 페이지 url 주소가 담겨있는 파일을 가져옵니다.\n",
    "    url_list = df['url'].tolist()\n",
    "    \n",
    "    for url in url_list :\n",
    "        response = requests.get(url)\n",
    "        # 사이트에 접속합니다.\n",
    "        bs = BeautifulSoup(response.content, 'html.parser')\n",
    "        # html 코드를 가져옵니다\n",
    "        \n",
    "        total = bs.find('div',class_='score_total').findChildren('em')[0].getText()\n",
    "        # 전체 리뷰 개수를 가져옵니다.\n",
    "        score_total = int(total.replace(',', ''))    # 쉼표 없애기 / int(정수형)로 만들기\n",
    "        pageCnt = score_total // 10     # 한페이지당 10개의 리뷰가 있어서\n",
    "        if score_total % 10 > 0 :\n",
    "            pageCnt += 1\n",
    "\n",
    "        # 전체 페이지를 돌면서 리뷰를 가져온다.\n",
    "        # 현재 페이지\n",
    "        now_page = 1\n",
    "\n",
    "        pageCnt = 100\n",
    "        # 영화 하나당 리뷰 100개페이지까지 수집. (1000개)\n",
    "        while now_page <= pageCnt :\n",
    "            sleep(1)\n",
    "            url2 = url + '&page=' + str(now_page)\n",
    "            # 요청할 페이지의 주소\n",
    "            \n",
    "            response2 = requests.get(url2)\n",
    "            bs2 = BeautifulSoup(response2.content, 'html.parser')\n",
    "\n",
    "            result_df = pd.DataFrame()\n",
    "            # 리뷰 데이터를 추출합니다.\n",
    "            \n",
    "            lis = bs2.select('.score_result li')\n",
    "            # li 태그들을 가져옵니다.(score_reple 태그-리뷰-를 포함하고 있는)\n",
    "            for obj in lis :\n",
    "            # score_result에는 한페이지에 10개의 리뷰가 있기떄문에 10개의 li가 존재합니다\n",
    "                star_score = obj.select('.star_score em')[0].text\n",
    "                # 평점\n",
    "                score_reple = obj.select('.score_reple p')[0].text\n",
    "                # 리뷰\n",
    "                score_reple = score_reple.replace('\\t','').replace('\\r','').replace('\\n','')\n",
    "                # 필요없는 부분을 제거합니다.\n",
    "                \n",
    "                result_df = result_df.append([[score_reple, star_score]], ignore_index=True)\n",
    "\n",
    "            if os.path.exists('star_score.csv') == False :     # 아직 파일이 없으면 파일을 만듭니다.\n",
    "                result_df.columns = ['text', 'score']\n",
    "                result_df.to_csv('star_score.csv', index=False, encoding='utf-8-sig')\n",
    "            else :                                               # 이미 파일이 있으면 결과를 더해줍니다.\n",
    "                result_df.to_csv('star_score.csv', index=False, encoding='utf-8-sig', mode='a', header=False)\n",
    "\n",
    "            now_page += 1\n",
    "            # 한 페이지가 끝나면 페이지수를 하나씩 늘려줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스크래핑 함수\n",
    "def scrapping() :\n",
    "\n",
    "    # 각 영화 코드 데이터를 가져와 저장합니다.\n",
    "    step1_get_detail_url()\n",
    "\n",
    "    # 리뷰 데이터가 있는 페이지의 주소를 저장합니다.\n",
    "    step2_get_reple_href()\n",
    "\n",
    "    # 리뷰 데이터를 가져옵니다\n",
    "    step3_get_reply_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('star_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>관람객보고나면 르네가 왜 아카데미 여주상인지 바로 알 수 있다는 ㅜㅜ 연기 쩔고 오...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>영화 끝나고 눈물이 눈물이 ㅜㅜ 정말 슬픈 삶을을 살았네요 주디 갈란드~먹고 싶은거...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>모두의 사랑을 받았으나 자신을 사랑하는 법을 몰랐던 '어른아이'의 아련한 비가(悲歌).</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>관람객생전 모르던 사람이 이렇게 안타까울수가...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>관람객반짝이는 주디 글자가 너무 슬프네요. 영화 끝나고도 여운이 안가셔서 밤새 같이...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>오즈의 마법사의 어린 소녀 도로시의 비극적인 삶이 잘드러나는 영화였다. 내가 어릴적...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>관람객오버더레인보우 나올때 눈물이.. 르네 젤위거 짱</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>르네 젤위거 명연기..</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>이런 영화 개봉 좀 해주지.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>르네젤위거를 브리짓존스로만 기억했었던걸 반상한다ㅠㅠ연기폭이 이렇게 넓은 배우였구나 ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score\n",
       "0  관람객보고나면 르네가 왜 아카데미 여주상인지 바로 알 수 있다는 ㅜㅜ 연기 쩔고 오...     10\n",
       "1  영화 끝나고 눈물이 눈물이 ㅜㅜ 정말 슬픈 삶을을 살았네요 주디 갈란드~먹고 싶은거...     10\n",
       "2  모두의 사랑을 받았으나 자신을 사랑하는 법을 몰랐던 '어른아이'의 아련한 비가(悲歌).       8\n",
       "3                       관람객생전 모르던 사람이 이렇게 안타까울수가...      10\n",
       "4  관람객반짝이는 주디 글자가 너무 슬프네요. 영화 끝나고도 여운이 안가셔서 밤새 같이...     10\n",
       "5  오즈의 마법사의 어린 소녀 도로시의 비극적인 삶이 잘드러나는 영화였다. 내가 어릴적...     10\n",
       "6                     관람객오버더레인보우 나올때 눈물이.. 르네 젤위거 짱      10\n",
       "7                                      르네 젤위거 명연기..      10\n",
       "8                                   이런 영화 개봉 좀 해주지.      10\n",
       "9  르네젤위거를 브리짓존스로만 기억했었던걸 반상한다ㅠㅠ연기폭이 이렇게 넓은 배우였구나 ...     10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 데이터 전처리 함수\n",
    "def text_preprocessing(text) :\n",
    "    if text.startswith('관람객') :\n",
    "        return text[3:]\n",
    "    # 일부 관람객 으로 시작하는 리뷰가 있어서 관람객이라는 부분을 제거해줍니다.\n",
    "    # 실제 리뷰 페이지를 가보시면 확인할 수 있습니다.\n",
    "    # https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=189001&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false\n",
    "    \n",
    "    elif text.startswith('스포일러가 포함된 감상평입니다.'):\n",
    "        return text[24:]\n",
    "    # 마찬가지로 스포일라거 포함된 감상평입니다.감상평 보기 라고 시작하는 부분이있습니다.\n",
    "    # 제거해줍니다\n",
    "    else :\n",
    "        return text\n",
    "    \n",
    "# 평점 전처리 함수\n",
    "def star_preprocessing(text) :\n",
    "    value = int(text)\n",
    "\n",
    "    if value > 8:\n",
    "        return '2' # 9,10 긍정\n",
    "    elif value < 5:\n",
    "        return '0' # 1,2,3,4 부정\n",
    "    else:\n",
    "        return '1'# 5,6,7,8 중립"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step4_data_preprocessing() :\n",
    "    df = pd.read_csv('star_score.csv')\n",
    "    \n",
    "    df['text'] = df['text'].astype(str)\n",
    "    # text데이터가 float형태로 저장되어있어 str형태로 변환해주니다.\n",
    "    df['text'].apply(text_preprocessing)\n",
    "    # 리뷰데이터 전처리를 실행합니다.\n",
    "    df['score'] = df['score'].apply(star_preprocessing)\n",
    "    # 평점데이터 전처리를 실행합니다.\n",
    "    \n",
    "    text_list = df['text'].tolist()\n",
    "    star_list = df['score'].tolist()\n",
    "\n",
    "    text_train, text_test, star_train, star_test = train_test_split(text_list, star_list, test_size=0.3, random_state=0)\n",
    "    # 리뷰 데이터와 평점 데이터를 각각 7:3으로 나누고 70%는 학습 데이터 30% 테스트 데이터로 사용합니다.\n",
    "\n",
    "    return text_train, text_test, star_train, star_test\n",
    "    # split한 데이터를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text) :\n",
    "    okt = Okt()\n",
    "    return okt.morphs(text)\n",
    "# okt라이브러리를 사용하여 형태소 분석을 실시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step5_learning(X_train, y_train, X_test, y_test):\n",
    "    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "    # TfidfVectorizer 방식으로 토큰화된 단어들의 tf-idf값을 계산합니다.\n",
    "    # lowercase : 소문자로 바꾸는 파라미터(한글 텍스트라서 필요없기떄문에 false)\n",
    "\n",
    "    logistic = LogisticRegression(C=10.0, penalty='l2', random_state=0)\n",
    "    # logisticregression \n",
    "\n",
    "    pipe = Pipeline([('vect', tfidf), ('clf', logistic)])\n",
    "    # vecter 데이터는 tfidf, 분류 데이터는 logisticgression으로 학습합니다\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    # train 데이터를 사용하여 학습합니다.\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    # 모델의 정확도를 측정합니다\n",
    "\n",
    "    with open('pipe.dat', 'wb') as fp :\n",
    "        pickled_data = pickle.dump(pipe, fp)\n",
    "    # 모델을 추후에 사용하기위해 pickle 이라는 데이터 저장 라이브러리를 사용하여 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning() :\n",
    "    text_train, text_test, star_train, star_test = step4_data_preprocessing()\n",
    "    # 리뷰 데이터의 70%는 text_train 30% text_test\n",
    "    # 평점 데이터의 70% star_train 30%는 star_test로 전처리를 시행합니다.\n",
    "    step5_learning(text_train, star_train, text_test, star_test)\n",
    "    # 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8086714399363564\n"
     ]
    }
   ],
   "source": [
    "learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step6_using_model() :\n",
    "    \n",
    "    with open('pipe.dat', 'rb') as fp:\n",
    "        pipe = pickle.load(fp)\n",
    "    # 이전에 만들어 놓은 모델을 다시 블러옵니다.\n",
    "    \n",
    "    while True :\n",
    "        text = input('리뷰를 작성해주세요 :')\n",
    "        # 문자를 입력할 수 있는 창을 만듭니다.\n",
    "\n",
    "        str = [text]\n",
    "\n",
    "        r1 = np.max(pipe.predict_proba(str) * 100)\n",
    "        # 예측 정확도\n",
    "        r2 = pipe.predict(str)[0]\n",
    "        # 예측 결과\n",
    "        \n",
    "        if text =='그만':\n",
    "            break\n",
    "        \n",
    "        if r2 == '2' :\n",
    "            print('긍정적인 리뷰')\n",
    "        elif r2 ==\"0\" :\n",
    "            print('부정적인 리뷰')\n",
    "        elif r2 =='1' :\n",
    "            print('중립적인 리뷰')\n",
    "        print('정확도 : %.3f' % r1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def using() :\n",
    "    step6_using_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰를 작성해주세요 :좋아요\n",
      "긍정적인 리뷰\n",
      "정확도 : 88.454\n",
      "리뷰를 작성해주세요 :재미없어요\n",
      "부정적인 리뷰\n",
      "정확도 : 95.438\n",
      "리뷰를 작성해주세요 :노잼\n",
      "부정적인 리뷰\n",
      "정확도 : 99.083\n",
      "리뷰를 작성해주세요 :그저그래요\n",
      "중립적인 리뷰\n",
      "정확도 : 63.698\n",
      "리뷰를 작성해주세요 :그닥\n",
      "부정적인 리뷰\n",
      "정확도 : 88.102\n",
      "리뷰를 작성해주세요 :그만\n"
     ]
    }
   ],
   "source": [
    "using()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
